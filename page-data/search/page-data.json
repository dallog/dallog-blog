{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"이 글은 우테코 달록팀 크루 '매트'가 작성했습니다. 달록에 적절한 패키지 구조 고민하기 우리는 프로젝트를 진행하며 어떠한 패키지 구조를 구성할지 고민하게 된다. 보통 패키지 구조를 나누는 대표적인 방법으로 , 로 나눌 수 있다. 계층별 패키지 구조 계층형 구조는 각 계층을 대표하는 패키지를 기준으로 코드를 구성한다. 계층형 구조의 가장 큰 장점은 해당 …","fields":{"slug":"/package-structure/"},"frontmatter":{"date":"July 18, 2022","title":"달록에 적절한 패키지 구조 고민하기","tags":["패키지 구조"]},"rawMarkdownBody":"\n> 이 글은 우테코 달록팀 크루 '[매트](https://github.com/hyeonic)'가 작성했습니다.\n\n## 달록에 적절한 패키지 구조 고민하기\n\n우리는 프로젝트를 진행하며 어떠한 패키지 구조를 구성할지 고민하게 된다. 보통 패키지 구조를 나누는 대표적인 방법으로 `계층별`, `기능별`로 나눌 수 있다.\n\n### 계층별 패키지 구조\n\n```json\n└── src\n    ├── main\n    │   ├── java\n    │   │   └── com\n    │   │       └── allog\n    │   │           └── dallog      \n    │   │               ├── application\n    │   │               ├── config\n    │   │               ├── domain\n    │   │               ├── dto\n    │   │               ├── exception\n    │   │               ├── presentation\n    │   │               └── DallogApplication.java\n    │   └── resources\n    │       └── application.yml\n```\n\n계층형 구조는 각 계층을 대표하는 패키지를 기준으로 코드를 구성한다. 계층형 구조의 가장 큰 장점은 해당 프로젝트에 대한 이해도가 낮아도 각 계층에 대한 역할을 충분히 숙지하고 있다면 전체적인 구조를 빠르게 파악할 수 있다.\n\n하지만 단점도 존재한다. 하나의 패키지에 모든 클래스들이 모이게 되기 때문에 규모가 커지면 클래스의 개수가 많아져 구분이 어려워진다. 아래는 이전에 계층형 구조를 기반으로 작성한 프로젝트이다.\n\n```json\n└── presentation  \n    ├── ChampionController.java\n    ├── CommentController.java\n    ├── PlaylistController.java\n    ├── RankingController.java\n    ├── SearchController.java\n    ├── UserController.java\n    ├── WardController.java\n    └── ...\n```\n\n비교적 적은 코드의 양이지만 규모가 커질수록 애플리케이션에서 presentation 계층에 해당하는 모든 객체가 해당 패키지에 모이게 될 것이다.\n\n### 기능별 패키지 구조\n\n기능별로 패키지를 나눠 구성한다. 기능별 패키지 구조의 장점은 해당 도메인에 관련된 코드들이 응집되어 있다는 점이다. 덕분에 `지역성의 원칙`를 잘 지킬 수 있다고 한다.\n\n> 컴퓨터 과학에서, 참조의 지역성, 또는 지역성의 원칙이란 프로세서가 짧은 시간 동안 동일한 메모리 공간에 반복적으로 접근하는 경향을 의미한다. 참조 지역성엔 두 가지 종류가 있다. 바로 시간적 지역성과 공간적 지역성이다. 시간적 지역성이란 특정 데이터 또는 리소스가 짧은 시간 내에 반복적으로 사용되는 것을 가리킨다. 공간적 지역성이란 상대적으로 가까운 저장 공간에 있는 데이터 요소들이 사용되는 것을 가리킨다.\n> \n\n개발자 역시 복잡하고 거대한 프로젝트의 전체 구조를 모두 인지하는 것은 힘든일이다. 우선 특정 지역의 흐름을 파악할 수 있다면 해당 패키지에 대해서는 마치 캐시에 적재된 데이터에 접근 하듯 빠르게 인지가 가능하다.\n\n```json\n└── src\n    ├── main\n    │   ├── java\n    │   │   └── com\n    │   │       └── allog\n    │   │           └── dallog\n    │   │               ├── auth\n    │   │               │   ├── application\n    |   |               |   ├── domain\n    │   │               │   ├── dto\n    │   │               │   ├── exception\n    │   │               │   └── presentation\n    │   │               ├── category\n    │   │               │   ├── application\n    |   |               |   ├── domain\n    │   │               │   ├── dto\n    │   │               │   ├── exception\n    │   │               │   └── presentation\n    │   │               ├── schedule\n    │   │               │   ├── application\n    |   |               |   ├── domain\n    │   │               │   ├── dto\n    │   │               │   ├── exception\n    │   │               │   └── presentation\n    │   │               ├── global\n    │   │               │   ├── config\n    │   │               │   ├── dto\n    │   │               │   ├── error\n    │   │               │   └── exception\n    │   │               ├── infrastructure\n    │   │               │   └── oauth\n    │   │               └── AllogDallogApplication.java\n    |   |\n    │   └── resources\n    │       └── application.yml\n```\n\n하지만 각 계층이 기능별로 모여 있기 때문에 프로젝트에 대한 이해도가 낮으면 전체 구조를 파악하는데 오랜 시간이 걸린다.\n\n### 더 나아가기\n\n현재 구조에서는 도메인에 해당하는 다양한 기능들이 패키지 전반적으로 퍼져 있다. 각각의 도메인 기능이 밀집되어 있지 않은 구조를 가지고 있다.\n\n```json\n└── src\n    ├── main\n    │   ├── java\n    │   │   └── com\n    │   │       └── allog\n    │   │           └── dallog\n    │   │               ├── domain\n    │   │               │   ├── auth\n    │   │               │   │   ├── application\n    |   |               │   |   ├── domain\n    │   │               │   │   ├── dto\n    │   │               │   │   ├── exception\n    │   │               │   │   └── presentation\n    │   │               │   ├── category\n    │   │               │   │   ├── application\n    |   |               │   |   ├── domain\n    │   │               │   │   ├── dto\n    │   │               │   │   ├── exception\n    │   │               │   │   └── presentation\n    │   │               │   └── schedule\n    │   │               │       ├── application\n    |   |               │       ├── domain\n    │   │               │       ├── dto\n    │   │               │       ├── exception\n    │   │               │       └── presentation\n    │   │               ├── global\n    │   │               │   ├── config\n    │   │               │   ├── dto\n    │   │               │   ├── error\n    │   │               │   └── exception\n    │   │               ├── infrastructure\n    │   │               │   └── oauth\n    │   │               └── AllogDallogApplication.java\n    |   |\n    │   └── resources\n    │       └── application.properties\n```\n\n### domain\n\n실제 애플리케이션의 핵심이 되는 도메인 로직이 모여 있다. 애플리케이션의 주요 비즈니스 로직이 모여 있기 때문에 `외부와의 의존성을 최소화`해야 한다. 즉 `외부의 변경에 의해 도메인 내부가 변경되는 것을 막아야 한다는 것`을 인지해야 한다.\n\n### global\n\n`global`은 프로젝트 전반에서 사용하는 객체로 구성한다. 공통적으로 사용하는 dto나 error, config에 대한 것들이 모여 있다. \n\n### infrastructure\n\n`infrasturcture`는 외부와의 통신을 담당하는 로직들이 담겨 있다. 이번 프로젝트에서는 OAuth를 활용한 회원 관리를 진행하기 때문에 google의 인증 서버와 통신이 필요해진다. 이 패키지는 우리의 의지와 다르게 외부의 변화에 따라 변경될 여지를 가지고 있다. 즉 변화에 매우 취약한 구조이며 외부 서버에 의존적 이기 때문에 항시 변화에 대응할 수 있도록 대비해야 한다. 이것이 의미하는 바는 결국 `도메인 관련 패키지에서 infrastructure를 직접적으로 의존하는 것`은 도메인 로직을 안전하게 지킬 수 없다는 의미를 내포한다.\n\n## 정리\n\n각각의 방법은 서로 다른 장단점을 가지고 있기 때문에 정답은 없다고 생각한다. 현재 프로젝트의 규모와 요구사항을 고려하여 선택해야 한다. 다만 선택한 패키지 구조에 충분한 근거를 가져야하고, 객체와 패키지 사이의 의존성에 대해 충분히 고민해야 한다.\n\n달록은 현재 기능별 패키지 구조로 진행되고 있다. 모든 팀원들이 처음 부터 기획과 설계에 대한 고민을 진행했기 때문에 프로젝트의 구조에 대해 분석 하는 시간이 불필요했기 때문이다. 하지만 각각의 기능들이 난잡하게 퍼져 있기 때문에 [더 나아가기](#더-나아가기)에서 언급한 것 처럼 좀 더 밀접한 기능들을 모아둘 필요가 있다고 판단한다. 이것은 추후 팀원들과 충분한 논의를 통해 개선해갈 예정이다.\n\n## References.\n\n[Spring Guide - Directory](https://cheese10yun.github.io/spring-guide-directory)<br>\n[지역성의 원칙을 고려한 패키지 구조: 기능별로 나누기](https://ahnheejong.name/articles/package-structure-with-the-principal-of-locality-in-mind)\n"},{"excerpt":"이 글은 우테코 달록팀 크루 '나인'이 작성했습니다. 🎯 \"무한 스크롤을 구현해보세요!\" 어떻게 구현하실 건가요? 무한 스크롤을 처음 마주했을때 🤔 저는 처음 무한 스크롤을 구현할 때 다음과 같은 방식을 사용했어요. scroll event 사용하기 우테코 레벨1 유튜브 미션 처음 제가 무한 스크롤을 구현했던 방법은 다음과 같습니다. 바로 스크롤 이벤트와 …","fields":{"slug":"/infinite-scroll/"},"frontmatter":{"date":"July 18, 2022","title":"React에서 무한 스크롤 구현하기","tags":["react"]},"rawMarkdownBody":"\n> 이 글은 우테코 달록팀 크루 '[나인](https://github.com/jhy979)'이 작성했습니다.\n\n🎯 \"무한 스크롤을 구현해보세요!\"\n\n어떻게 구현하실 건가요?\n\n## 무한 스크롤을 처음 마주했을때\n\n🤔 저는 처음 무한 스크롤을 구현할 때 다음과 같은 방식을 사용했어요.\n\n```\n1. scroll 이벤트를 감지한다.\n\n2. 현재 스크롤 영역의 `위치를 계산`한다.\n\n3. 영역 계산을 통해 페이지 아래에 위치하면 API 요청을 진행한다.\n\n4. 받아온 데이터를 추가하여 다시 렌더링한다.\n\n5. 무한 반복\n```\n\n---\n## scroll event 사용하기\n\n[우테코 레벨1 유튜브 미션](https://github.dev/jhy979/javascript-youtube-classroom/tree/jhy979-step2)\n\n처음 제가 무한 스크롤을 구현했던 방법은 다음과 같습니다.\n\n바로 스크롤 이벤트와 offset을 이용한 방식이죠!\n\n```js\n  scrollToBottom(callback) {\n    const isScrollBottom =\n      this.$videoList.scrollHeight - this.$videoList.scrollTop <=\n      this.$videoList.offsetHeight + EVENT.SCROLL.OFFSET;\n\n    if (isScrollBottom) {\n      callback(this.$searchInput.value);\n    }\n  }\n```\n메서드 네이밍을 통해서도 알 수 있듯이, 화면 하단까지 내려갔을 경우 (offset 정도를 감안하여) 인자로 받은 함수를 실행시켜주었습니다.\n\n아 물론, 스크롤 이벤트는 워낙 많이 발생하기 때문에 throttle을 걸어주었습니다. (이건 필수죠)\n\n😢 하지만, `documentElement.scrollTop`, `documentElement.scrollHeight`, `documentElement.offsetHeight`는 리플로우(Reflow)가 발생합니다.\n\n확실히 비효율적이겠죠!\n\n---\n\n## IntersectionObserver 사용하기\n\n달록에서는 무한 스크롤을 구현할 때 [Intersection Observer](https://developer.mozilla.org/ko/docs/Web/API/Intersection_Observer_API)를 사용했습니다. \n\n> Intersection Observer는 쉽게 말해 지정한 대상이 화면에 보이는지 감시하고 판단하는 도구입니다.\n\n브라우저 Viewport와 Target으로 설정한 요소의 교차점을 관찰하여 그 Target이 Viewport에 포함되는지 구별하는 기능을 제공합니다. \n\n<img src=\"https://velog.velcdn.com/images/jhy979/post/19500233-65fc-4ba9-b421-81516700c00b/image.png\" />\n\n\n### useIntersect 커스텀훅\n\n> 가장 먼저 useIntersect 라는 커스텀훅을 제작했습니다. \n\n이 커스텀훅은 `인자로 intersect시 실행할 함수`를 받고 `ref를 제공`하여 관찰할 대상을 지정할 수 있습니다.\n\n```ts\ntype IntersectHandler = (entry: IntersectionObserverEntry, observer: IntersectionObserver) => void;\n\n// 인자로 onIntersect와 options를 받습니다.\n// onIntersect는 intersect 발생 시 실행하고 싶은 함수입니다.\nfunction useIntersect(onIntersect: IntersectHandler, options?: IntersectionObserverInit) {\n  // 관찰하고 싶은 친구를 잡기 위해 ref를 만들어주세요.\n  const ref = useRef<HTMLDivElement>(null); \n  \n  // intersect 시 실행할 함수를 만들어줍시다.\n  const callback = useCallback(\n    (entries: IntersectionObserverEntry[], observer: IntersectionObserver) => {\n      entries.forEach((entry) => {\n        if (entry.isIntersecting) {\n          onIntersect(entry, observer);\n        }\n      });\n    },\n    [onIntersect]\n  );\n\n  // 🔨 옵저버에게 일을 시켜봅시다.\n  useEffect(() => {\n    \n  \t// 우리가 관찰하고 싶은 친구가 없으면 그냥 return 해버려요.\n    if (!ref.current) {\n      return;\n    }\n\t\n    // 관찰할 대상이 있으면 옵저버 데꼬 와야죠!\n    const observer = new IntersectionObserver(callback, options);\n\t\n    // 이 옵저버한테 감시를 시킵시다.\n    observer.observe(ref.current);\n\n    // 할 일 끝나면 고생한 옵저버도 쉬게 해줍시다!\n    return () => {\n      observer.disconnect();\n    };\n    \n  }, [ref, options, callback]);\n\n  return ref;\n}\n\nexport default useIntersect;\n```\n\n### 실제 사용\nuseIntersect 커스텀훅을 잘 만들었으니 이제 이 커스텀훅을 무한 스크롤에 사용해 봅시다.\n\n![](https://velog.velcdn.com/images/jhy979/post/4643727c-852d-4f23-ab4f-44ce79e2e3b2/image.gif)\n\n다음은 카테고리 목록을 계속 불러와 리스트를 보여주는 컴포넌트입니다.\n```tsx\nfunction CategoryList({ categoryList, getMoreCategories, hasNextPage }: CategoryListProps) {\n  \n  // useIntersect 커스텀훅의 인자로 (교차 시) 실행할 함수를 넣어줍시다.\n  const ref = useIntersect(() => {\n    hasNextPage && getMoreCategories();\n  });\n\n  return (\n    <div css={categoryTable}>\n      <div css={categoryTableHeader}>\n        <span> 생성 날짜 </span>\n        <span> 카테고리 이름 </span>\n      </div>\n      \n      {categoryList.map((category) => (\n        <CategoryItem key={category.id} category={category} />\n      ))}\n      \n      // 페이지 하단까지 내리면 이 친구가 등장하여 옵저버에게 감지될 거예요.\n      <div ref={ref} css={intersectTarget}></div>\n    </div>\n  );\n}\n\n```\n💪 무한 스크롤함에 따라 props로 받아오는 categoryList가 길어지게 될텐데요, 다행히 React에서는 key값으로 변경 여부를 확인하기 때문에 새롭게 추가된 리스트들만 리렌더링해주었습니다.\n"},{"excerpt":"이 글은 우테코 달록팀 크루 '매트'가 작성했습니다. Git-flow git 브랜치 전략 중 하나이다, 이것은 어떠한 기능을 나타내는 것이 아니라 방법론이다. 각각의 프로젝트와 개발 환경에 따라 알맞게 수정하여 사용해야 한다. 이 게시글은 git을 알고 사용해 본 경험이 있다는 것을 전제로 작성하였다. 또한 직접 프로젝트에 적용하고 연습하고 있기 때문에 …","fields":{"slug":"/git-branch-strategy/"},"frontmatter":{"date":"July 12, 2022","title":"달록팀의 git 브랜치 전략을 소개합니다.","tags":["git","git-flow"]},"rawMarkdownBody":"\n> 이 글은 우테코 달록팀 크루 '[매트](https://github.com/hyeonic)'가 작성했습니다.\n\n## Git-flow\n\ngit 브랜치 전략 중 하나이다, 이것은 어떠한 기능을 나타내는 것이 아니라 방법론이다. 각각의 프로젝트와 개발 환경에 따라 알맞게 수정하여 사용해야 한다.\n\n이 게시글은 git을 알고 사용해 본 경험이 있다는 것을 전제로 작성하였다. 또한 직접 프로젝트에 적용하고 연습하고 있기 때문에 정답이 될 수 없고, 지속적으로 개선할 예정이다.\n\n## Git Repository\n\n프로젝트에 적용하기 앞서 어떠한 형태로 Git Repository가 구성되는지 살펴보았다.\n\n![](./git-repository.png)\n\n### Upstream Remote Repository\n\n개발자가 공유하는 저장소로 최신 소스코드가 저장되어 있는 원격 저장소이다.\n\n#### 적용하기\n\n이러한 Remote Repository 생성을 위하여 github에 New organization을 사용히였다.\n\n![](./new-organization.png)\n\n다양한 기능을 제공하는 Team과 Enterprice는 월마다 일정 금액을 사용해야 한다. 하지만 간단한 프로젝트 진행을 위해 생성하였기 때문에 Free만 사용하여도 충분한 실습과 프로젝트를 진행할 수 있다.\n\n![](./fare.png)\n\norganization을 생성하게 되면 소속된 repository를 생성할 수 있다. 이것을 `Upstream Remote Repository`로 적용한다.\n\n### A's, B's, C's Origin Remote Repository\n\n`Upstream Repository`를 Fork한 원격 개인 저장소이다. Upstream Repository를 직접 clone하여 작업하는 것이 아니라 각각의 팀원들이 `Fork`를 하여 원격 저장소를 생성하고 그것을 clone하여 `Local Repository`를 생성하여 작업한다.\n\n이렇게 두 개의 remote repository로 나눈 이유는 Upstream repository의 경우 `팀원이 공유`하고 있는 Repository이기 때문에 다양한 시도를 하기에 큰 위험 부담을 가지고 있다. 각자의 개인 repository에서 `작업을 시도`한 후 적절한 기능 merge 하기 위해 `Pull Request`를 요청한다.\n\n### 운영 방식\n\ngit-flow는 기본적으로 5가지의 브랜치를 사용하여 운영한다.\n\n * `main`: 제품으로 출시될 수 있는 브랜치\n * `develop`: 다음 출시 버전을 개발하는 브랜치\n * `feature`: 기능을 개발하는 브랜치\n * `release`: 이번 출시 버전을 준비하는 브랜치\n * `hotfix`: 출시 버전에서 발생한 버그를 수정하는 브랜치\n\n![](./git-flow-dev.png)\n\n`main`과 `develop` 브랜치이다. 두 브랜치는 항시 운영되어야 하는 브랜치이다. `develop`는 개발을 위한 브랜치이고, `main`은 제품으로 출시될 수 있는 브랜치 이기 때문에 `항시 배포 가능한 상태`이어야 한다.\n\n`main`과 `develop`은 `Upstream remote repository`에서 운영한다.\n\n![](./git-flow-feature.png)\n\n`feature` 브랜치는 단위 기능을 개발하는 브랜치이다. 기능 개발이 완료되면 `develop` 브랜치와 `merge` 된다.\n\n`develop`은 모든 팀원이 `공유`하는 브랜치이다. feature는 각자 맡아 작성한 코드들이 들어 있는 브랜치이다. merge 작업 전에 팀원들 간의 `지속적인 코드 리뷰`가 필요하다.\n\n그렇기 때문에 `Pull Request`를 사용하여 `merge` 작업 전 리뷰어들에게 코드 리뷰를 받고 반영 사항을 수정하여 commit 후 merge 한다. 이 과정은 `협업에서 가장 중요한 부분`이라고 생각된다.\n\n![](./git-flow-release.png)\n\n`release` 브랜치는 배포를 하기 전에 충분한 검증을 위해 생성하는 브랜치이다. 배포 가능한 상태가 되면 `main` 브랜치로 `merge` 작업을 거친다. 또한 `develop`에도 반영사항을 모두 `merge` 시켜야 한다.\n\n![](./git-flow-hotfix.png)\n\n`hotifx` 브랜치는 배포 중 버그가 생겨 긴급하게 수정해야 하는 브랜치이다. 배포 이후에 이루어지는 브랜치이고, 반영 사항을 `main`과 `develop`에 모두 적용 시켜야 한다.\n\n앞서 말했듯이 `main`과 `develop`는 항시 운영되는 브랜치이다. 이 둘을 제외한 나머지 브랜치 들은 제 역할이 마무리 되어 `merge` 작업이 완료되면 브랜치를 삭제하여 정리한다.\n\n### 간단히 적용해보기\n\n`Upstream Remote Repository`를 기반으로 원격 개인 저장소에 `Fork` 해야 한다.\n\n![](./fork.png)\n\nOrganization에 생성한 repository에 Fork를 누르면 손쉽게 할 수 있다. Fork로 생성된 repository를 기반으로 `Local Repository`를 생성해야 한다.\n\n```bash\ngit clone https://github.com/{개인 github 이름}/{repository 이름}.git\n```\n\ngit clone을 사용하여 원격 저장소에 있는 repository를 손쉽게 clone할 수 있다.\n\n```bash\n$ git remote -v\n\norigin  https://github.com/{github 사용자 이름}/{repository 이름}.git (fetch)\norigin  https://github.com/{github 사용자 이름}/{repository 이름}.git (push)\n```\n\nclone 받은 local repository를 git remote -v로 확인해보면 원격 저장소가 등록되어 있는 것을 확인 할 수 있다. 매번 최신 코드를 `fetch` 및 `rebase` 하기 위해서는 `Upstream`을 등록해야 한다.\n\n```bash\n$ git remote add upstream https://github.com/{organization 이름}/{repository 이름}.git\n\n$ git remote -v\n\norigin  https://github.com/{github 사용자 이름}/{repository 이름}.git (fetch)\norigin  https://github.com/{github 사용자 이름}/{repository 이름}.git (push)\nupstream        https://github.com/{organization 이름}/{repository 이름}.git\nupstream        https://github.com/{organization 이름}/{repository 이름}.git\n```\n\n`git remote add upstream`을 통하여 upstream을 등록한다. 정상적으로 등록 된 것을 확인할 수 있다. 이제 작업할 때 마다 브랜치를 생성하고 최신 코드를 pull 받아야 한다.\n\n우리 팀원은 각각 개발해야 하는 기능을 github issue에 등록한 후 등록 번호를 기반으로 브랜치를 생성하기로 하였다.\n\n우선 간단한 예시를 위하여 이슈를 등록한다.\n\n![](./issue.png)\n\n3번 번호가 부여된 이슈라고 가정한다. 해당 번호를 기반으로 `local repository`에서 feature 브랜치를 생성한다.\n\n```bash\n$ git branch feature/3-init-setting\n$ git checkout feature/3-init-setting\n```\n\n이제 Upstream에 있는 remote repository에서 최신 소스코드를 받아 와야 한다.\n\n```bash\n$ git fetch upstream\n$ git rebase upstream/develop\n```\n\ngit pull을 사용하여 등록한 upstream develop에서 commit 기록을 병합한다. 이제 신나게 작업을 진행하고 자신의 원격 저장소인 `Origin remote repository`에 push한다.\n\n```bash\n$ git push origin feature/3-init-setting\n```\n\n그렇게 github repository를 살펴보면 `변경을 감지`하고 pull request를 생성할 것인지에 대한 탭을 확인할 수 있다.\n\n![](./upstream-repository.png)\n\n이제 fork한 개인 원격 저장소를 살펴보면 새롭게 작성한 브랜치를 감지하고 pull request 작성을 위한 버튼이 생성된다.\n\n![](./pull-request.png)\n\n`feature/3-init-setting` 브랜치를 develop에 merge하기 위한 pull request를 진행하는 예시이다. 작성한 코드를 리뷰해줄 팀원들을 선택하고, commit한 코드의 내용을 간단히 요약하여 작성한다. 이제 생성한 PR을 기반으로 `코드리뷰`를 진행한다. 변경 사항이 적용되면 develop에 반영하기 위해 merge한다.\n\n### 달록에 맞게 수정하기\n\ngit-flow는 빠르게 급변하는 웹 서비스에는 맞지 않은 git 브랜치 전략이다. 관리해야 할 브랜치가 늘어나기 때문에 개발자들이 신경써야 할 포인트가 늘어난다. \n\n빈번한 배포로 인해 급작스러운 이슈가 발생할 수 있다. 즉 예상치 못한 롤백이 자주일어날 수 있다. 또한 웹 서비스의 특성상 다양한 릴리즈 버전을 유지할 필요가 없다. 이러한 특성들로 인해 웹 서비스에는 다소 보수적인 git-flow 전략은 맞지 않을 수 있다.\n\n그럼에도 우리 달록팀은 git-flow를 선택했다. 우리는 실제 운영할 수 있는 서비스를 개발하며 다양한 경험을 습득해야 한다. 또한 대부분의 팀원들이 git에 익숙하지 않았으며 다양한 시도를 통해 빠르게 학습해야 한다. \n\n대신 git-flow를 정석적으로 사용하지 않고 필요한 부분을 수정하여 반영하려 한다. 현재 수준에서 `develop`에서 대부분의 빌드를 진행하기 때문에 `release` 브랜치의 필요성이 다소 옅어졌다. 결국 `release`를 제외한 `main`, `develop`, `feature`, `hotfix`만 사용하기로 결정하였다.\n\n### 달록이 집중한 것\n\n달록의 팀 각 구성원들은 맡은 이슈를 기반으로 브랜치를 생성한 뒤 작업을 진행할 것이다. 결국 다수의 브랜치가 아래와 같이 병렬적으로 커밋이 쌓이게 된다.\n\n![](./force-push.png)\n\n만약 팀원 중 한명이 작업을 끝내서 PR이 merge된 상황이라고 가정하자. develop 브랜치의 커밋 베이스는 변경됬으며 이전에 작업을 진행하던 브랜치들은 시작점이 뒤로 밀려나게 된다. \n\n여러 사람이 하나의 저장소를 기반으로 작업을 진행하기 때문에 함께 사용하는 공간의 코드들은 충돌을 야기할 가능성이 크다. 즉 지속적인 `fetch` + `rebase`를 통해 사전에 충돌에 대비하며 항상 `develop` 브랜치와 커밋 싱크를 맞춘다.\n\n정리하면 위 그림과 같이 항시 develop 브랜치의 끝 단에서 시작해야 한다. 이러한 방식은 코드의 충돌을 최소화할 수 있으며 순차적인 git 커밋 목록을 기반으로 쉽게 기능이 추가된 것을 확인할 수 있다.\n\n## 정리\n\n지금까지 간단히 `git-flow의 흐름`과 이것을 기반으로 `달록에 적용한 과정`들을 알아보았다. git-flow는 언급한 것 처럼 부가적인 브랜치로 인해 `관리에 대한 부담감`을 느낄 수 있다. 하지만 `upstream`과 `origin`을 분리한 환경은 좀 더 도전적인 과제들을 적용하기에 매우 좋은 환경을 구성해준다. 또한 `pull request`를 통한 코드 리뷰를 통해 보다 더 양질의 애플리케이션 개발에 힘쓸 수 있다.\n\n## References.\n\n[git flow; 환상과 현실 그 사이에 서비스](https://vallista.kr/git-flow;-%ED%99%98%EC%83%81%EA%B3%BC-%ED%98%84%EC%8B%A4-%EA%B7%B8-%EC%82%AC%EC%9D%B4%EC%97%90-%EC%84%9C%EB%B9%84%EC%8A%A4/)<br>\n[우린 Git-flow를 사용하고 있어요](https://woowabros.github.io/experience/2017/10/30/baemin-mobile-git-branch-strategy.html)<br>\n"},{"excerpt":"이 글은 우테코 달록팀 크루 '후디'가 작성했습니다. 배경 우테코 레벨3 달록 팀에서 메소드의 파라미터에는 반드시  키워드를 붙이도록 컨벤션을 정했습니다. 이유는 무엇일까요? 일반적으로 가변적인 변수는 프로그램의 흐름을 예측하기 어렵게 만든다. 따라서 변수를 가변적으로 만드는 것이 중요한데, 자바에서는 변수의 재할당을 막기 위해  키워드를 사용합니다. 물…","fields":{"slug":"/intellij-final-keyword/"},"frontmatter":{"date":"July 12, 2022","title":"IntelliJ에서 메소드 추출한 메소드의 파라미터에 final 키워드 자동 추가하기","tags":["intellij"]},"rawMarkdownBody":"\n> 이 글은 우테코 달록팀 크루 '[후디](https://github.com/devHudi)'가 작성했습니다.\n\n## 배경\n\n우테코 레벨3 달록 팀에서 메소드의 파라미터에는 반드시 `final` 키워드를 붙이도록 컨벤션을 정했습니다. 이유는 무엇일까요? 일반적으로 가변적인 변수는 프로그램의 흐름을 예측하기 어렵게 만든다. 따라서 변수를 가변적으로 만드는 것이 중요한데, 자바에서는 변수의 재할당을 막기 위해 `final` 키워드를 사용합니다. 물론 `final` 키워드 하나만으로 완전한 불변을 보장하도록 만들수는 없지만, 어느정도 예측 가능한 코드를 만드는데에는 도움이 됩니다.\n\n이는 메소드의 파라미터에도 적용됩니다. 아래의 코드는 `Memo` 객체를 생성하기 위한 생성자입니다. `value` 라는 String 값을 전달받아 객체 필드에 할당합니다.\n\n```java\npublic Memo(String value) {\n    validateLength(value);\n\n    value = \"hello\"; // 예상치 못한 코드\n\n    this.value = value;\n}\n```\n\n하지만 위처럼 예상치 못한 코드가 추가되면 어떻게 될까요? `value` 필드에는 개발자가 의도하지 못한 값이 할당될 것 입니다.\n\n```java\npublic Memo(final String value) {\n    validateLength(value);\n\n    value = 1; // error: final parameter value may not be assigned\n\n    this.value = value;\n}\n```\n\n이를 보완하기 위해서 위처럼 메소드 파라미터에 `final` 키워드를 붙이면, 재할당 시 컴파일 에러가 발생하여 예상치 못한 동작을 사전에 방지할 수 있을 것 입니다.\n\n## IntelliJ 설정하기\n\n하지만, 저희는 아직 메소드 파라미터에 `final` 키워드를 붙이는 습관이 들어있지 않았습니다. 따라서 IDE의 도움이 필요한데요, 다행히도 IntelliJ에서 메소드 추출 리팩토링을 할 때 생성되는 메소드 파라미터에 자동으로 `final` 키워드를 붙여주는 옵션을 발견하였습니다.\n\n![IntelliJ 설정 화면](./intellij.png)\n\n맥 기준으로 Preferences → Editor → Code Style → Java 페이지에서 Code Generation 탭을 클릭합니다. 해당 탭의 하단에 ‘Final Modifier’ 에서 ‘Make generated parameters final’ 을 체크해줍니다. 위와 같이 옵션을 변경하면 메소드 추출 시 파라미터에 자동으로 `final` 키워드가 생성되는 모습을 확인할 수 있습니다 😊\n"},{"excerpt":"이 글은 우테코 달록팀 크루 '리버'가 작성했습니다. JPA 등장배경 1990년대 인터넷이 보급되면서 온라인 비지니스가 활성화 되었다.\n자연스럽게, 온라인 비지니스에서 DB에 데이터를 저장하고 가져올때 사용할 Connection Connector에 대한 니즈가 높아졌다.\n그래서 각 언어들에서 DB Connection을 지원하는 API 기술들이 등장하였다.…","fields":{"slug":"/appearance-background-of-jpa/"},"frontmatter":{"date":"July 07, 2022","title":"JPA 등장배경","tags":["JPA"]},"rawMarkdownBody":"\n> 이 글은 우테코 달록팀 크루 '[리버](https://github.com/gudonghee2000)'가 작성했습니다.\n\n## JPA 등장배경\n\n1990년대 인터넷이 보급되면서 온라인 비지니스가 활성화 되었다.\n자연스럽게, 온라인 비지니스에서 DB에 데이터를 저장하고 가져올때 사용할 Connection Connector에 대한 니즈가 높아졌다.\n그래서 각 언어들에서 DB Connection을 지원하는 API 기술들이 등장하였다. 이후에 Spring에서는 DB Connection을 좀 더 쉽게 관리하는 Spring JDBC API를 만들고 지원하였다. (이외에도 Query문을 XML파일을 통해 관리하게끔 도와주는 Mybatis도 등장하였음)\n하지만, 여전히 쿼리문을 개발자가 직접 작성해야하는 등 다양한 문제를 가지고 있었다.\n그래서 JAVA 진영에서는 개발자가 쿼리문을 직접 작성하지 않아도 프레임워크 내부에서 지원해주는 ORM(Object Relational Model)기술인 JPA가 등장하였다.\n그렇다면, JPA 이전에 개발자들이 직접 쿼리문을 작성하던 SQL 중심적인 개발의 단점은 무엇이 있을까?\n아래에서 살펴보자.\n\n## SQL 중심적인 개발의 단점\n\n#### 1. 쿼리문 무한 반복과 지루한 코딩\n\nJDBC API는 쿼리문을 개발자들이 직접 작성 해야한다.\n그래서 개발자들은 쿼리문을 작성하는 지루한 작업을 개발 과정에서 무한반복해야한다.\n\n#### 2. 객체의 필드가 추가되면 모든 쿼리문을 수정해야한다.\n\n![](https://velog.velcdn.com/images/gudonghee2000/post/488a7899-d55b-4447-aafc-bada8d840192/image.jpg)\n위 그림과 같이 SQL 중심적인 개발에서는 객체의 필드가 변경되면 해당하는 모든 쿼리문을 찾아 개발자가 수정해야한다.\n\n#### 3. 객체와 관계형 DB의 패러다임의 불일치\n\n객체라고 하면 떠오르는 키워드는 무엇이 있을까?\n캡슐화, 협력, 의존, 상속, 참조 등의 기술이 있다. 그런데, DB에서는 이러한 기술들이 없다.\n적용되는 기술들의 패러다임 불일치로 인해 개발자들은 SQL 지향적인 개발을 할 수 밖에 없다.\n아래에서 자세히 살펴보자.\n\n## 객체와 관계형 DB의 패러다임 차이\n\n객체와 관계형 DB는 연관관계를 통해 작업을 수행한다는 공통점을 가진다.\n하지만 연관관계를 맺는 패러다임의 차이를 가진다.\n\n객체는 상속, 참조를 통해 연관관계를 맺는다.\n반면 관계형 DB는 PK, FK를 통해 연관관계를 맺는다.\n이때, 연관관계를 맺는 방식의 차이로 발생하는 문제점을 코드와 함께 살펴보자.\n\n```java\npublic class Crew {\n   private Long id;\n    private String name;\n    private String nickName;\n    private Team team;\n}\n\npublic class Team {\n   private Long id;\n    private String team_name;\n}\n```\n\n위와 같이 `Crew` 객체가 `Team` 객체를 필드로 가지고 참조한다고 하자.\n객체지향적인 관점에서, `Crew`와 `Team`의 관계를 위와 같이 표현하는것은 자연스럽다.\n\n하지만, DB에서는 `Crew`가 `Team`을 참조한다는 개념이 없다.\n그래서 위 객체들을 가지고 DB의 `Crew`테이블과 `Team`테이블의 관계를 맺을때, 아래와 같이 `PK` 값인 id를 `FK`로 가지도록 구현 하여야한다.\n![ERD](./erd.png)\n\n연관관계에 대해서 객체의 구조와 DB의 구조가 달라진다는 것이다.\n\n그렇다면 객체지향적인 연관관계를 가진 객체들을 DB에 저장 할 때,\nDB의 연관관계로 변경하는 것이 왜 문제가 될까?\n\n## 객체와 RDB의 연관관계 차이가 가져오는 문제\n\n위에서 봤던 `Crew`와 `Team`의 객체 모델링을 다시한번 살펴보자.\n\n```java\npublic class Crew {\n   private Long id;\n    private String name;\n    private String nickName;\n    private Team team;\n}\n\npublic class Team {\n   private Long id;\n    private String team_name;\n}\n```\n\n위와 같이 모델링된 `Crew`와 `Team`을 DB에 저장한다고 한다면 다음의 과정이 필요하다.\nDB에 접근하고자 하는 Dao 객체는 `Crew`객체를 분해하고 각자 `Crew` 테이블과 `Team` 테이블에 대한 쿼리를 작성해야한다. 단순히 `Crew`의 객체정보를 저장하는데 3가지 과정을 거쳐야한다.\n\n이러한 복잡한 과정을 피하는 방법은 없을까?\n아래 코드를 살펴보자.\n\n```java\npublic class Crew {\n   private Long id;\n    private String name;\n    private String nickName;\n    private Long team_id;\n}\n\npublic class Team {\n   private Long id;\n    private String team_name;\n}\n```\n\n위와 같이 DB 테이블 구조에 맞추어 `Crew`와 `Team` 객체를 설계하는 방법이있다.\n이러한 객체 모델링은 Dao 객체를 통해 데이터를 DB에 저장 할 때, `Crew` 객체를 분해하는 과정을 삭제 할 수 있다.\n객체가 DB 구조에 맞추어 설계되어 있기 때문이다.\n\n**하지만, 객체 모델링을 할 때 객체가 서로 참조하는 객체지향적인 개발이 아닌\nDB 테이블구조에 맞추어 개발하는 SQL 중심적인 개발을 하게 된다는 문제를 가진다.**\n\n객체와 관계형 DB의 연관관계의 패러다임 차이는 객체를 객체답지 못하게 만든다는 것이다.\n그렇다면, 패러다임의 차이를 해결하는 방법은 없을까?\n\n## JPA\n\n객체와 관계형 DB의 패러다임의 차이로 인해 우리는 객체지향적인 프로그래밍을 하지못하고 DB에 종속적인 개발을 하게된다.\n이러한 문제를 해결하기 위해 JAVA진영에서는 JPA를 제공한다.\n\nJPA를 통해 개발자는 더이상 쿼리문을 반복적으로 작성하거나 유지보수하는 것을 신경쓰지 않아도 된다.\n왜냐하면 JPA가 쿼리문을 작성해주기 때문이다.\n그리고 SQL 중심적인 개발에서 벗어나 객체지향적인 개발을 할 수 있게 된다.\n왜냐하면 패러다임의 불일치를 JPA가 내부적으로 맵핑해주기 때문이다.\n\n다음 포스팅에서는 JPA의 작동 메커니즘을 자세히 살펴보자.\n"},{"excerpt":"이 글은 우테코 달록팀 크루 '리버'가 작성했습니다. Rest Docs Spring Rest Docs는 테스트 코드 기반으로 자동으로 Rest API 문서를 작성 할 수 있도록 도와주는 프레임 워크이다. Rest Docs와 Swagger 자바 문서 자동화에는 주로 Rest Docs와 Swagger가 사용된다.\n각 자동화 프레임 워크의 장단점을 살펴보자.\n…","fields":{"slug":"/apply-rest-docs/"},"frontmatter":{"date":"July 07, 2022","title":"MockMvc를 사용한 Spring RestDocs","tags":["Spring","Rest API"]},"rawMarkdownBody":"\n> 이 글은 우테코 달록팀 크루 '[리버](https://github.com/gudonghee2000)'가 작성했습니다.\n\n## Rest Docs\nSpring Rest Docs는 테스트 코드 기반으로 자동으로 Rest API 문서를 작성 할 수 있도록 도와주는 프레임 워크이다.\n\n## Rest Docs와 Swagger\n자바 문서 자동화에는 주로 Rest Docs와 Swagger가 사용된다.\n각 자동화 프레임 워크의 장단점을 살펴보자.\n![](https://velog.velcdn.com/images/gudonghee2000/post/ffc0e7eb-3190-43ca-9a85-16f9b8bbbb4e/image.JPG)\n\nSwagger는 API 문서의 작성을 위해 프로덕션 코드에 추가적인 코드를 작성해야한다. \n그래서 Swagger의 사용은 프로덕션 코드의 가독성을 떨어트린다고 생각한다.\n\n반대로, Spring Rest Docs는 테스트 코드에 의존적이기 때문에 Spring Rest Docs를 사용하는것이 좋다고 생각한다.\n\n## MockMvc vs Rest Assured\nSpring Rest Docs를 사용하여 문서를 작성 하려면 테스트 코드가 필요하다.\n테스트 코드를 작성 할 때, 대표적으로 MockMvc와 Rest Assured를 사용한다.\n\nMockMvc를 사용하면  `@WebMvcTest`로 테스트 할 수 있다.\n그래서 Controller Layer만으로 테스트 하기 때문에 테스트 속도가 빠르다.\n\n반면, RestAssured는 `@SpringBootTest`로 수행해야한다. 그러면 전체 어플리케이션 컨텍스트를 로드하여 빈을 주입하기에 테스트 속도가 느리다.\n하지만, 실제 객체를 통한 테스트가 가능하기 때문에 테스트의 신뢰성이 높다.\n\n통합 테스트, 인수 테스트의 경우 RestAssuerd가 좋을 수 있지만, 문서를 작성하기 위한 테스트에는 MockMvc가 더 적절하다고 생각한다.\n\n**_💡 @WebMvcTest와 @SpringBootTest_**\n@WebMvcTest는 Application Context를 완전하게 Start하지 않고 Present Layer 관련 컴포넌트만 스캔하여 빈 등록한다.\n반면, @SpringBootTest의 경우 모든 빈을 로드하여 등록한다.\n\n\n## AsciiDoc\n\nSpring Boot Rest Docs는 Asciidoc를 문서 번역을 위한 텍스트 프로세서로 사용한다.\n\n## Rest Docs API 문서 생성 매커니즘\n우선, Rest Docs의 문서 생성 매커니즘을 살펴보자.\n\n1. MockMvc로 작성한 테스트 코드를 실행한다.\n\n2. 테스트가 통과하면 아래와 같이 `build/generated-snippets` 하위에 스니펫(문서조각)들이 생성된다. \n![](https://velog.velcdn.com/images/gudonghee2000/post/f4555336-cc43-4cc7-b7ca-8c1f903b2afd/image.png)\n\n   _❗❗ gradle은 build/generated-snippets에 스니펫이 생성된다._\n\n3. `build/generated-snippets` 하위에 생성된 스니펫들을 묶어서 HTML 문서를 만들기 위해서는, gradle의 경우 아래와 같이`src/docs/asciidoc` 하위에 스니펫들을 묶은 adoc문서를 만든다.![](https://velog.velcdn.com/images/gudonghee2000/post/bc769cd9-2fd2-483d-8c65-a4885f628e37/image.png)\n\n4. 스니펫을 이용해서 `src/docs/asciidoc` 하위에 adoc 파일을 생성했다면, `./gradlew build` 명령어를 통해 빌드를 해준다.\n![](https://velog.velcdn.com/images/gudonghee2000/post/f1948f04-9742-4267-8d19-3d962097f129/image.png)\n빌드가 완료되면 위와 같이 `resources - static - docs` 하위에 HTML 문서가 생성된다.\n\n5. 어플리케이션을 실행 한 후, `http://localhost:8080/docs/{HTML 파일명}` 을 웹브라우저에 검색하면 생성한 REST API 문서를 확인 할 수 있다. \n\n\t**❗❗ API문서 url은 코드를 통해 변경 가능하다.**\n    \n### ❗유의할 점\nresources - static - docs 하위의 HTML 파일은 실제로는 build.gradle의 설정파일에 따라서 위와같이 build - docs - asciidoc 하위의 HTML 파일을 복사해온 파일이다.\n![](https://velog.velcdn.com/images/gudonghee2000/post/7b70d45e-15a7-4278-9e3a-033370c2a600/image.png)\n\n### 아이디어\nREST API 문서를 확인할 때, `http://localhost:8080/docs/{HTML 파일명}` 을 통해서 웹브라우저에 접근하지 않아도 확인하는 방법이 있다.\n![](https://velog.velcdn.com/images/gudonghee2000/post/8f5177d6-5ba0-4f3e-be3a-3cba37012c46/image.png)\nAsciiDoc 플러그인을 설치하면 위와같이, 인텔리제이 상에서도 REST API 문서를 실시간으로 확인할수 있다.  (✔설치 추천)\n\n## Rest Docs 사용을 위한 빌드파일 설정\n``` java\nplugins {\n    id 'org.asciidoctor.jvm.convert' version '3.3.2' // 1\n}\n\next {\n    snippetsDir = file('build/generated-snippets') // 2\n}\n\ntest { \n    outputs.dir snippetsDir // 3\n    useJUnitPlatform()\n}\n\nconfigurations {\n    asciidoctorExtensions\n}\n\nasciidoctor { // 4\n    configurations 'asciidoctorExtensions' \n    inputs.dir snippetsDir \n    dependsOn test\n}\n\ndependencies {\n    testImplementation 'org.springframework.restdocs:spring-restdocs-mockmvc' // 5\n    asciidoctorExtensions 'org.springframework.restdocs:spring-restdocs-asciidoctor' // 6\n}\n\ntask copyDocument(type: Copy) { // 7\n    dependsOn asciidoctor\n    \n    from file(\"build/docs/asciidoc\")\n    into file(\"src/main/resources/static/docs\")\n}\n\t\nbootJar { \n    dependsOn copyDocument // 8\n}\n  ```\n\n\n1. gradle7부터 사용하는 플러그인으로 asciidoc 파일 변환, build 디렉토리에 복사하는 플러그인이다.\n\n2. 생성된 스니펫을 저장할 위치를 정의한다. gradle은 `build/generated-snippets`에 스니펫이 생성된다.\n\n3. 테스트 Task의 결과 아웃풋 디렉토리를 `build/generated-snippets`로 지정한다.\n\n4. asciidoctor Task가 사용할 인풋 디렉토리를 `build/generated-snippets`로 지정한다.\n\tdependsOn test로 문서가 작성되기 전에 테스트가 실행되도록 한다.\n    \n5. MockMvc를 테스트에 사용하기 위한 의존성을 추가 해준다.\n\n6. 일반 텍스트를 처리하고 HTML 파일을 생성하는 의존성을 추가 해준다.\n\n7. asciidoctor Task로 생성한 `build/docs/asciidoc`파일을 `src/main/resources/static/docs`로 복사한다.\n\n8. bootJar 실행시 copyDocument를 먼저 실행하도록 한다.\n\n\n--- \n\n✅MockMvc를 사용한 Rest Docs 테스트 작성을 알아보기 전에 우선 MockMvc에 대해 알아보자.\n\n##MockMvc 기본 메서드\n어떠한 것들이 있는지 알아보고 밑에서 자세히 알아보자.\n\n### perform()\n가상의 request를 처리한다.\n\n```java\nmockMvc.perform(get(\"/api/schedules/?year=2022&month=7\"))\n```\n\n### andExpert()\nandExpert()\n\n예상값을 검증한다. \n\n```java\n.andExpect(status().isOk())\n// status 값이 정상인 경우를 기대하고 만든 체이닝 메소드의 일부\n\n.andExpect(content().contentType(\"application/json;charset=utf-8\"))\n//contentType을 검증\n```\n\n### andDo()\n요청에 대한 처리를 맡는다. print() 메소드가 일반적이다.\n\n```java\n.andDo(print())\n```\n\n### andReturn()\n테스트한 결과 객체를 받을 때 사용한다.\n\n```java\nMvcResult result = mockMvc.perform(get(\"/\"))\n.andDo(print())\n.andExpect(status().isOk())\n.andReturn();\n```\n\n## MockMvc 요청 만들기\n요청을 만들 때는 static 메서드인 get, post, put, delete, fileUpload 등을 이용해서 MockHttpServletRequestBuilder 객체를 생성하는 것에서 시작한다.\n\nMockHttpServletRequestBuilder는 ServletRequest를 구성하기에 필요한 다양한 메서드를 제공한다.\n![](https://velog.velcdn.com/images/gudonghee2000/post/ee7412c0-3698-4e26-9ad2-ce826495d20e/image.JPG)\n위 메서드들은 메서드 체이닝을 지원하기 때문에, 아래와 같이 요청 데이터를 연결해서 작성하면된다.\n\n\n```java \n@Test\n    void test() throws Exception {\n        MockHttpServletRequestBuilder builder = get(\"/api/schedules\")\n                .param(\"year\", \"2022\")\n                .param(\"month\", \"7\")\n                .accept(MediaType.APPLICATION_JSON)\n                .header(\"sessionId\", \"세션아이디입니다.\");\n\n        mockMvc.perform(builder)\n                .andExpect(status().isOk());\n    }\n\n```\n_**❗❗ 유의 할 점**_\nMockMvc.perform() 의 파라미터 값이 MockHttpServletRequestBuilder의 상위 객체이다. \n\n그래서 perform() 파라미터로 아래와 같이 넣어주어도 작동된다.\n```java\n@Test\n    void test() throws Exception {\n        mockMvc.perform(get(\"/api/schedules\")\n                .param(\"year\", \"2022\")\n                .param(\"month\", \"7\")\n                .accept(MediaType.APPLICATION_JSON)\n                .header(\"sessionId\", \"세션아이디입니다.\"))\n                .andExpect(status().isOk());\n    }\n```\n\n## MockMvc 실행 결과 검증\nperform()은 반환 값으로 ResultActions가 반환된다.\nResultActions의 andExpect는 요청 실행 결과를 검증 하려면 ResultMatcher를 넘겨줘서 검증해야한다.\nResultMatcher는 다음의 MockMvcResultMatchers가 가지는 static 메서드를 통해서 얻는다.\n\nMockMvcResultMatchers는 다음의 static 메서드를 통해 다양한 ResultMatcher를 제공한다.\n\n![](https://velog.velcdn.com/images/gudonghee2000/post/f1d670a7-c355-4c1c-9d01-2d84ea6412b7/image.JPG)\n\n아래의 예시를 살펴보자.\n```java\n\t@Test\n    void test() throws Exception {\n        mockMvc.perform(builder)\n                .andExpect(handler().handlerType(ScheduleController.class))\n                .andExpect(handler().methodName(\"save\"))\n                .andExpect(forwardedUrl(\"index\"))\n                .andExpect(header().stringValues(\"Content-Language\", \"en\"))\n                .andExpect(model().attribute(\"message\", \"저장이 잘되었습니다.\"))\n                .andExpect(status().isOk());\n    }\n```\n\n## MockMvc 실행 결과 처리\n실행 결과를 출력할 떄는 andDo 메서드를 사용한다.\nandDo 메서드 의 인수에는 실행 결과를 처리 할 수 있는 ResultHandler를 지정한다.\nMockMvcResultHandlers는 다양한 ResultHandler를 제공하지만 print()를 주로 사용한다.\n\n\n## MockMvc를 사용한 Rest Docs 생성\n테스트 코드와 함께 MockMvc를 사용한 Rest Docs 생성을 알아보자.\n\n```java\n@WebMvcTest(ScheduleController.class)\n@AutoConfigureRestDocs // 1\nclass ScheduleControllerTest {\n\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Autowired\n    private ObjectMapper objectMapper;\n\n    @MockBean // 2\n    private ScheduleService scheduleService;\n\n    @Test\n    void save() throws Exception {\n        // given\n        ScheduleCreateRequest request = new ScheduleCreateRequest(\"제목\", LocalDateTime.now(), LocalDateTime.now(), \"메모\");\n\n        given(scheduleService.save(request))\n                .willReturn(1L); // 3\n\n        // when & then\n        mockMvc.perform(post(\"/api/schedules\")\n                        .content(objectMapper.writeValueAsString(request))\n                        .contentType(MediaType.APPLICATION_JSON)\n                        .accept(MediaType.APPLICATION_JSON))\n                .andExpect(status().isOk())\n                .andDo(document(\"schedule-save\", // 4\n                        requestFields(\n                                fieldWithPath(\"title\").type(JsonFieldType.STRING).description(\"제목\"),\n                                fieldWithPath(\"startDateTime\").type(JsonFieldType.STRING)\n                                        .description(\"2022-07-04T13:00\"),\n                                fieldWithPath(\"endDateTime\").type(JsonFieldType.STRING).description(\"2022-07-05T07:00\"),\n                                fieldWithPath(\"memo\").type(JsonFieldType.STRING).description(\"메모입니다.\")\n                        )\n                ));\n    }\n}\n```\n\n1. target/generated-snippets dir 생성하고 테스트 코드를 통해 snippets를 추가해주는 애노테이션이다.\n\n2. `ScheduleService`를 mocking을 하기위해서 `@MockBean` 을 선언한다.\n\n3. mocking을 통해 `ScheduleService` 를 통해 받을 응답값을 설정한다.\n\n4. test 수행시 `andDo(document(\"xxx\"))`를 통해서 `./build/generated-snippets` 하위에 문서가 작성된다.\n\n\n---\n## 끝내면서 \n이상 Rest Docs의 매커니즘, 설정 그리고 MockMvc를 활용한 Rest Docs 생성 방법을 살펴보았다.\n프로젝트에 RestAssuered를 사용한 Rest Docs를 적용하면서 테스트 격리에 문제를 경험하였는데,\n테스트 격리에 대해서 추후에 포스팅 해봐야겠다.\n"}]}},"pageContext":{}},"staticQueryHashes":[]}